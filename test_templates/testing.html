<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Hand Detection and Cropping</title>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
  <style>
    body { text-align: center; background: #222; color: white; }
    canvas, video { display: 1; } /* Hide raw video/canvas */
  </style>
</head>
<body>
  <h1>Hand Crop + Teachable Machine</h1>
  <video id="input_video" width="640" height="480" autoplay></video>
  <canvas id="output_canvas" width="640" height="480"></canvas>
  <canvas id="hand_canvas" width="224" height="224"></canvas> <!-- For hand crop -->

  <script>
    const URL = "https://teachablemachine.withgoogle.com/models/sejlB6-6N/"; // <-- Put your model URL here
    let model;

    // Setup video
    const videoElement = document.getElementById('input_video');
    const outputCanvas = document.getElementById('output_canvas');
    const handCanvas = document.getElementById('hand_canvas');
    const outputCtx = outputCanvas.getContext('2d');
    const handCtx = handCanvas.getContext('2d');

    async function loadModel() {
      model = await tmImage.load(URL + "model.json", URL + "metadata.json");
      console.log("Model Loaded");
    }

    // Setup MediaPipe Hands
    const hands = new Hands({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
    });

    hands.setOptions({
      maxNumHands: 1,
      modelComplexity: 1,
      minDetectionConfidence: 0.7,
      minTrackingConfidence: 0.5
    });

    hands.onResults(onResults);

    // Start webcam
    const camera = new Camera(videoElement, {
      onFrame: async () => {
        await hands.send({image: videoElement});
      },
      width: 640,
      height: 480
    });
    camera.start();

    function onResults(results) {
      outputCtx.save();
      outputCtx.clearRect(0, 0, outputCanvas.width, outputCanvas.height);
      outputCtx.drawImage(results.image, 0, 0, outputCanvas.width, outputCanvas.height);

      if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
        const landmarks = results.multiHandLandmarks[0];

        // Get bounding box
        let minX = Infinity, minY = Infinity, maxX = -Infinity, maxY = -Infinity;
        for (const point of landmarks) {
          minX = Math.min(minX, point.x);
          minY = Math.min(minY, point.y);
          maxX = Math.max(maxX, point.x);
          maxY = Math.max(maxY, point.y);
        }

        // Expand a bit around the hand
        const offset = 0.1;
        minX = Math.max(0, minX - offset);
        minY = Math.max(0, minY - offset);
        maxX = Math.min(1, maxX + offset);
        maxY = Math.min(1, maxY + offset);

        const x = minX * outputCanvas.width;
        const y = minY * outputCanvas.height;
        const width = (maxX - minX) * outputCanvas.width;
        const height = (maxY - minY) * outputCanvas.height;

        // Crop the hand
        const handImage = outputCtx.getImageData(x, y, width, height);
        handCanvas.width = 224;
        handCanvas.height = 224;
        handCtx.clearRect(0, 0, handCanvas.width, handCanvas.height);
        handCtx.drawImage(
          outputCanvas, 
          x, y, width, height, 
          0, 0, handCanvas.width, handCanvas.height
        );

        predictHand();
      }
      outputCtx.restore();
    }

    async function predictHand() {
      const prediction = await model.predict(handCanvas);
      console.log(prediction);
    }

    loadModel();
  </script>
</body>
</html>
